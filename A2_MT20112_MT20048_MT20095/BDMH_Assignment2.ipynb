{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e3fdd9",
   "metadata": {},
   "source": [
    "# Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4ccd2a7",
   "metadata": {
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../Dataset/RNA_Train.csv')\n",
    "df_test = pd.read_csv('../Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977d5279",
   "metadata": {},
   "source": [
    "# Map character to number (peptides encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8ae235",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def charToNumEncoding(peptide):\n",
    "    i = 0\n",
    "    for character in peptide:\n",
    "        mapping[character] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7e399",
   "metadata": {},
   "source": [
    "# Creating list of list of instances of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e82997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def traindataEncoding(data):\n",
    "    Features = []\n",
    "    row = len(data)\n",
    "    for i in range(row):\n",
    "        l = []\n",
    "        sequence = data['Sequence'][i]\n",
    "        for character in sequence:\n",
    "            l.append(mapping[character])\n",
    "        l.append(data['label'][i])\n",
    "        Features.append(l)\n",
    "    #print(Features)\n",
    "    return Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb40e6f",
   "metadata": {},
   "source": [
    "# Creating list of list of instances of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90840cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testdataEncoding(data):\n",
    "    Features = []\n",
    "    row = len(data)\n",
    "    for i in range(row):\n",
    "        l = []\n",
    "        sequence = data['Sequence'][i]\n",
    "        for character in sequence:\n",
    "            l.append(mapping[character])\n",
    "        Features.append(l)\n",
    "    #print(Features)\n",
    "    return Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53086fe7",
   "metadata": {},
   "source": [
    "# Data Imbalance handling using Random oversampling on minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263612c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Oversampling(x_train,y_train):\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = oversample.fit_resample(x_train, y_train)\n",
    "    print(\"x-shape :\",X_resampled.shape,\"\\ny-shape :\", y_resampled.shape)\n",
    "    return X_resampled,y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f17d9e",
   "metadata": {},
   "source": [
    "# Data Imbalance handling using ADASYN(Adaptive Synthetic Oversampling) on minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5584bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oversampling2(x_train, y_train):\n",
    "    adasyn = ADASYN(sampling_strategy='minority')\n",
    "    X_resampled, y_resampled = adasyn.fit_resample(x_train, y_train)\n",
    "    print(\"x-shape :\", X_resampled.shape, \"\\ny-shape :\", y_resampled.shape)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5ea60",
   "metadata": {},
   "source": [
    "# RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24dfb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RandomForest(x,y,test_df):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test_df)\n",
    "    return y_pred  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f6418",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd684f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def XGBoost(x,y,test_df):\n",
    "    clf = XGBClassifier()\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test_df)\n",
    "    return y_pred  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e261005",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f30c454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(x, y, test_df):\n",
    "    param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']}\n",
    "    clf = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose=2)\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test_df)\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb54a9",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4844908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LightGBM(x, y, test_df):\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "    }\n",
    "    clf = GridSearchCV(LGBMClassifier(), param_grid, refit=True, verbose=2)\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test_df)\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a130955",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea365214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegressionModel(x, y, test_df):\n",
    "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "    clf = GridSearchCV(LogisticRegression(), param_grid, refit=True, verbose=2)\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test_df)\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf08c64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipelining of RandomForest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31576e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Pipelining(x,y,test_df):\n",
    "    model = [('lr', RandomForestClassifier()), ('XG', make_pipeline(StandardScaler(), XGBClassifier()))]\n",
    "    clf = StackingClassifier(estimators=model)\n",
    "    clf.fit(x, y)\n",
    "    y_pred = clf.predict(test_df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e0dd6ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GenerateCSV(y_pred):\n",
    "    df3 = pd.read_csv('../Dataset/test.csv')\n",
    "    df3['label'] = y_pred\n",
    "    compress = dict(method='zip', archive_name='result.csv')\n",
    "    df3.to_csv('result.zip', index=False, compression=compress)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b70d592",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': 0, 'M': 1, 'L': 2, 'Q': 3, 'V': 4, 'R': 5, 'A': 6, 'G': 7, 'T': 8, 'W': 9, 'F': 10, 'P': 11, 'S': 12, 'C': 13, 'N': 14, 'E': 15, 'K': 16, 'H': 17, 'I': 18, 'Y': 19, 'D': 20}\n"
     ]
    }
   ],
   "source": [
    "mapping = {}      # dictionary where key = character and value = numeric\n",
    "\n",
    "charToNumEncoding('XMLQVRAGTWFPSCNEKHIYD')     # RNA Sequence\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63818c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(traindataEncoding(df_train))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b421ca3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
       "0   0   0   0   0   0   0   0   0   1   2   3   2   4   5   6   7   6   0\n",
       "1   0   0   0   0   0   0   0   1   2   3   2   4   5   6   7   6   5   0\n",
       "2   0   0   0   0   0   0   1   2   3   2   4   5   6   7   6   5   8   0\n",
       "3   0   0   0   0   0   1   2   3   2   4   5   6   7   6   5   8   9   0\n",
       "4   0   0   0   0   1   2   3   2   4   5   6   7   6   5   8   9  10   0\n",
       "5   0   0   0   1   2   3   2   4   5   6   7   6   5   8   9  10   5   0\n",
       "6   0   0   1   2   3   2   4   5   6   7   6   5   8   9  10   5  11   0\n",
       "7   0   1   2   3   2   4   5   6   7   6   5   8   9  10   5  11  12   0\n",
       "8   1   2   3   2   4   5   6   7   6   5   8   9  10   5  11  12   7   0\n",
       "9   2   3   2   4   5   6   7   6   5   8   9  10   5  11  12   7  13   0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f933b600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17\n",
      "5299  20  20   2  15   7   4  20   7  20   8  15   6   4   5  18   6  12   0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.loc[[5299]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7835343a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df =  pd.DataFrame(testdataEncoding(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef3258a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16\n",
       "0   0   0   0   0   0   0   0   0  12  15   4  12  20   8  14   2  19\n",
       "1   0   0   0   0   0   0   0  12  15   4  12  20   8  14   2  19  12\n",
       "2   0   0   0   0   0   0  12  15   4  12  20   8  14   2  19  12  11\n",
       "3   0   0   0   0   0  12  15   4  12  20   8  14   2  19  12  11  10\n",
       "4   0   0   0   0  12  15   4  12  20   8  14   2  19  12  11  10  16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75f05d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = train_df.loc[:, :16]       # independent variable\n",
    "y_train = train_df[17]               # dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fda281",
   "metadata": {},
   "source": [
    "# Checking data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dec1d5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "0    291963\n",
      "1     38899\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "count = y_train.value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a56984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "categories = pd.unique(y_train)\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "colors = {'Non Interacting':'red', 'Interacting':'green'}         \n",
    "labels = list(colors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "plt.bar(categories, count, color=colors.values())\n",
    "plt.xlabel(\"Class\",fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\",fontweight=\"bold\")\n",
    "plt.title(\"Interacting and Non-Interacting RNA Sequences\\n\",fontweight=\"bold\")\n",
    "plt.legend(handles, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b28405",
   "metadata": {},
   "source": [
    "# Handling data imbalnce using oversampling on minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccd696bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-shape : (583926, 17) \n",
      "y-shape : (583926,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "x_resampled, y_resampled = Oversampling(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fdab20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-shape : (578673, 17) \n",
      "y-shape : (578673,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "x_resampled, y_resampled = Oversampling2(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "117fc1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "0    291963\n",
      "1    286710\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count = y_resampled.value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2913c95d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAAHrCAYAAACzRh4YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABfHklEQVR4nO3deVxUdf/+8WtYBnAZUBGRxC3LfV+QFssk0bQ0rdQs0VzSsPs2yq0FlxbN6tYsl9u6E7vvzLTSShMzFc0kFwRTU9PEzBS1FFBUFDi/P/xxvowsAqIc9fW8H/O4Z855zznvM2dOw+U58xmbYRiGAAAAAACW41LaDQAAAAAA8kZgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwAYAAAAAFkVgA4ACHDhwQDabTTabTffee29pt1Mqsre/Zs2apd0KSgnHAQCUHgIbcJMaP368+QdY//79i72chIQEjR8/XuPHj1dMTEyJ9XctRUVFmduQnJxc2u1c13K+r2w2m7799lun+f379zfnzZ49u5S6/D8cB//nejoOcr7Hsm9lypRRgwYNNGrUKJ08edKpPiYmxql21KhRTvOjoqLMeb17985znZMnT3ZaxtChQ4vcd2xsrLp16yY/Pz+5u7vL19dXDRs21OOPP65PP/20yMsDcHNwK+0GAFzfEhISNGHCBPPx9fiv71FRUVq7dq2ki4HCx8fHnFe1alX98MMPkiRvb+/SaO+69vrrr+uBBx4o7TauOo6D0nf27Fnt2rVLu3bt0po1a/TTTz/J1dU1z9pZs2ZpzJgxqlixYqGXf2mg+uKLL/T+++/Lza1wf0qtWrVKnTp1UkZGhjnt77//1t9//61ffvlFx44dU58+fQrdD4CbB4ENwHXhzJkzKlOmzDVfr4eHh+66665rvt4bxYYNG7R69Wrdd999pd3KDYHjILdFixapUqVK+uGHHzRu3DhJ0pYtWxQbG5tvz6dPn9a0adM0ceLEQq1j165d+vnnn52m/fXXX/r+++/VqVOnQi0jMjLSDGvPPPOMHnzwQWVkZGj//v1avXq10tPTC7UcADcfLokE4CTnJWJz587VtGnTVKdOHXl4eKhp06ZavXq1WVuzZk0NGDDAfDxhwgTzuePHjzenJyYmavDgwapRo4Y8PDzk5+enXr16adeuXU7rznlZ0vjx4zV79mzVrVtX7u7uWrhwoSTp+eef1x133KGqVavKw8ND5cqVU4sWLfT22287/ct1tp9++kmPPvqoAgICZLfb5e/vrwceeEAJCQnmZVLZZxUkqVatWmYPBw4cyPe7O0V5nbJ9/vnnatSokTw9PdWoUSMtXLjQaTlRUVGX3T9F2f6c3z3bu3evHnroIZUrV04VK1bU0KFDde7cOaf6v/76S/369ZO3t7d8fHzUr18//fXXX5ft6XJee+21QtXt27dPAwYMUGBgoOx2uypVqqQHHnhAq1atcqrLeXlb//79tWLFCrVu3Vqenp6qXr26pk+ffsU9cxxY+zjIqVWrVmrfvr0iIyPVuHFjc/off/xR4PPee+89paamFmodOc+u5bxkcsGCBYXuc+vWrZKkihUrasaMGerUqZO6du2qf/zjH1qyZIm++OKLXM/5+eef1adPH1WtWlV2u1233HKLBg0apEOHDuWqjY+P17333isvLy9Vq1ZNEyZM0Pfff5/nJb/33nuv0/7NVtB+KGwvxXlP/PHHHxo+fLjq1KkjT09PVahQQcHBwfrss8+K1cPZs2c1cuRI3XbbbfLw8FDZsmVVq1Yt9ejRQ4sXL85z/wCWZgC4KY0bN86QZEgywsLC8pxeu3Zt8372rXz58saJEycMwzCMGjVq5JqffRs3bpxhGIYRFxdn+Pj45FlTrlw5Y+PGjea6586dm++6586daxiGYXh4eOS7zgEDBjht40cffWS4urrmWTt37lxjzZo1+S5LkpGYmGgkJiaaj++5555ivU6GYRhffPGFYbPZctU1bdo01zYWpCjbnz3d4XAYlSpVylX/0ksvmbXp6elG8+bNc9U0adLEvF+jRo3L9pfzdWnVqpV5f8OGDYZhGEZYWJg5bdasWebzNm7caJQvXz7P7bLZbMbMmTPN2pz7rUaNGoaLi0uu56xcufKyvV7aL8fB9XMcXNpftkaNGpnTY2JizOk5t/H2228332uvv/56rte8V69eudZXp04dQ5Lh5uZmJCUlGb6+vuaxde7cucv2axiGUblyZXMdY8aMMbZv325kZWXlW//tt9/mu5/9/f2N/fv3m7W//vqr4XA4Cnxdc76/77nnnjxfv5z7M+d+KEovRX1PxMfHGxUrVsxz2Tl7LkoPTz31VL7v5759+xZqfwFWwhk2APnav3+/Ro8era+//lpNmzaVJJ06dUrz58+XdPFfyl988UWzfsCAAfrhhx/0ww8/6KmnnpJhGAoLCzMHMHj++ef13Xff6c0335Srq6tOnz6tAQMGyDCMPNcdGhqqJUuWaOHChWrYsKEk6aWXXtKnn36q6OhoxcTE6Msvv1RQUJCki2cmsv+l9c8//9SwYcOUmZkpSerevbsWL16szz//XIMHD5bdblfz5s31ww8/qFmzZuZ6Fy1aZG5D1apVS+R1yszM1IgRI8ztfPTRR7Vs2TL94x//0LZt2wq1jmyF3f6cUlNTVblyZX3xxRd69dVXzen//ve/zftz585VfHy8JKlSpUr66KOPtGjRIp0+fbpI/eXUoUMHtW3bVpKc1nspwzA0YMAAnTp1SpL0yCOPaNmyZXrllVfk4uIiwzA0YsSIPM+Y/P7773rwwQf1zTffOJ35yLltV4rjwHrHQU5btmxRTEyMJk6cqB07dkiSGjRokO/lkBUqVNAzzzwjSZo6darS0tIuu/x9+/ZJktq3b68qVaqoe/fuki4eW5cOrJOfkJAQ8/7kyZPVuHFjVahQQQ899JA+++wzp/1/5swZhYWFKT09XW5ubnr99df13XffmYOlJCUlmdsgSa+88op5trB58+ZasmSJ3nvvPe3du7dQvRWkqL3kdLn3hGEY6tevn06cOCFJatSokf773/9q2bJlioyMVKVKlYrVw1dffSVJqlGjhj7//HN99913+s9//qN+/fqpQoUKV/yaANdcaSVFAKWrMGcWunXrZk5fsGCBOX3EiBHm9Jz/Mp19NiFbfHy8Oa9Zs2bGDz/8YN6Cg4PNeVu2bMm1rBo1ahgXLlzI1ff69euNbt26Gf7+/oabm1uufz396quvDMMwjKlTp5rT7rjjjgJfi/z+tdkwjEKdWbjc67Rx40anfwk+f/68Wd+2bdsinVko7PYbhvNZiPj4eHN6vXr1zOnJycmGYRhG586dzWkzZswwa1euXOm0Ty4n5+syevRo45tvvnHaz3mdYdu6dWu+r0/Pnj3NeVOnTjUMw/lsiZ+fn3mGIykpyen9li3n+y77lv0cjoP/cz0dB5dub85bjx49jMOHDzvV53zPBAUFGUePHjXKlCljSDLefvvtAs+wPf/88+a8f//734ZhGEZ0dLQ57bHHHrtsv4ZhGH/++afRsmXLAvvOtnjxYnN6586dnd4zNWvWNKSLZ56PHz9uZGZmGuXKlTPrd+7caS7npZdeyvP9XZQzbEXp5dJlXO49kfPYcDgcxrFjx/J87Yrag7+/vyFdPMMYHx9f6LOggFUx6AiAfN1zzz3m/ex/6ZRU6CG/f/31V/N+QkKC7r777jzrdu3apZYtWzpN69SpU67R1zZt2qT27dvrwoUL+a4zu7ec6+7SpUuh+i2uy71O+/fvN6e1aNFC7u7u5uPg4GD99NNPhVpPUbY/J4fD4XT25NIevb29nXps3bq1eb9NmzaF6i0/Xbt2VfPmzRUfH6/XXnstzxEGc+6rS1+fNm3amN/tyVmXrW3btvLw8JCU/3s0r/ddYmJioX9XjuOgcK7VcXA5W7Zs0alTpwo8M+jn56chQ4Zo2rRpeueddxQZGZlnnWEY5veoXF1d9fDDD0u6ePa4YsWKOnHihJYuXaq0tDSVLVu2wL4CAgIUGxur5cuXa/HixVq7dq0SExPN+V9++aW+++47dezY0Wm/LV++XMuXL8+zt927d6tOnTrmmfCyZcuqQYMGZs2VHr+SitTLpWc1L/eeyLnsoKAgVa5cuUR6GDhwoF5//XVt27ZNzZs3l6urq26//XZ16tRJI0eOLPRZY8AquCQSQL5yXjqS849GI49Lt65EXpckValSJde02bNnm3+kdu3aVd9++61++OEH9evXz6zJysoq0d4Koyivk81mK/Z6irv9l14CVJR9eSX9ZnvppZckXbxMKfuStcK63PqvxXuU46BwrtVxcKnExEQdO3ZMjzzyiCTp4MGDevzxxy+7f0aOHCkPDw8dOXJEH330UZ4169evNy8vzczMlJ+fn2w2m9zd3c3L+M6cOWNegnc57u7ueuihhzR37lzt379f27dvV7169cz52QOTFNblLufM73XOOT37cllJVzTIUF69XKtj59IeXn31VX366ad69NFHVbduXdlsNu3atUtTp05Vx44d8xyYB7AyAhuAK+Li8n//Gbn0j8Tbb7/dvH/PPffIMIxct7S0ND399NO5lpvXHxp//vmneX/SpEnq3Lmz7rrrLh09ejRXbc51X+47JgVtQ0m49dZbzfvx8fFOfyDFxsYWejlF2f6iql27tnl/y5Yt5v2NGzde8bJ79OihBg0ayDAMxcXF5Zqfc1/Fx8c7/TGVc/0564oir/ddYc+uFRbHweWV1HGQl8qVK+uDDz4wA0JcXNxlQ1RAQIA5uufmzZvzrCnsj1kXZrTI5cuX53pdGzVqpM6dO5uPs1+TnPstLCws3/dMaGio/Pz8zLN7aWlpTqOO5nf85jzTnZSUJOniPl+5cmWu2qL0UlQ5l71p06Z8A2Nxeujdu7cWLlyo3bt369SpU2ag37FjR55n6wEr45JIAFck57+gRkdHq127dvL09FTjxo3VtGlTNWrUSDt27NDatWvVr18/Pfroo3J3d9eBAwe0adMmLV68WCdPnizUumrUqGHenzRpksLCwrR8+XKtWLEiV+2jjz6qMWPGKD09XT/++KN69uypfv36mX+U3Hnnnerbt2+ubfjggw/0wAMPyMvLS61atSruy+KkRYsWCgwM1B9//KHDhw+rX79+6tu3r1asWFGky8CKsv1F9dBDD5mXGUVGRsrLy0vlypXT2LFjr3jZNptNL774op544ok85zdr1kz169fXrl27dOTIEfXt21f9+/fXxo0bzSG47Xa7evbsecW9XC0cB5dXUsdBfnx8fPT0009r8uTJkqQpU6aYg4PkZ8yYMfrwww/zPOOSkZGhzz//XNLF9/Dbb78tu93uVDN27FidPn1aK1as0MmTJwsc0CJ7kJdevXqpTZs28vHx0e7duzV37lyzJvty5Pvvv1+VK1fW8ePH9fHHH6tixYq6//77lZmZqQMHDujHH3/Utm3b9Msvv8jFxUVdu3Y1L9188skn9corr+jPP//UtGnT8uylTp065v1nn31WgwYN0tKlS/MMMkXppahyHhspKSnq0KGDRo0apYoVKyouLk4nT57UO++8U+Qe7rzzTjVv3lxt2rTRLbfcolOnTjn1x2/e4bpzlb4bB8DiCjPYQs4v/+f80n7O+uPHj+c51PKaNWsMwyh4OPPsW7aCBm4wjIuDFlw6JLjNZnMauCFnzx988EGeQ75fWvfee+/lmp89wEZhBlsozOuU33DmjRs3LvRgC0Xd/ku3JVteAw6kp6c7DQGefbvtttvyXU5eLh10JFtGRoY5NHr2rSSG9c/5Ghe0zYXpl+Pg+jgODCP/Yf3//PNPw93d3Zy3fv36XP0EBQU5Lat///5Oy8sedCTnwCItW7bMs4/u3bubNR9++GGBPd9yyy0F7v/27ds7DfO/bNmyAn++Ied7PL9h/XP+LEfO/fDLL7/k+Z7IOSBRzv1QlF6K+p4o6NjIWVeUHm699dZ86xo0aGBkZGQUuK8Aq+GSSABXxNfXV0uWLFHz5s3l5eWVa36LFi2UkJCgoUOHqnbt2rLb7fLx8VGjRo00dOjQXD+KXJA2bdpo8eLFaty4sTw9PdWwYUMtWrRIHTt2zLN+0KBB+uGHH9SjRw9VqVJFbm5u8vPzU+fOnZ0G4Xj66ac1evRoVa9e3emysJLUo0cPLVy4UA0aNJDdblf9+vU1f/58dejQwawpU6ZMgcso6vYXhd1u18qVK9W3b185HA45HA499thjiomJueJlSxcHbCjobF2bNm0UFxensLAw3XLLLXJzc1OFChXUqVMnfffddxo2bFiJ9HG1cBwUTkkcBwUJCAhQnz59zMdTpky57HNefPFFubq65pqe83LIhx56KM/nPvjgg+b9y10WuWDBAo0ZM0bBwcGqVq2a7Ha7ypQpo2bNmun111/Xt99+63QJ7AMPPKAtW7boySefVLVq1eTu7i5fX181a9ZMERERWrRokVl72223ac2aNWrXrp08PDxUtWpVvfzyy3rnnXfy7KV+/fr65JNPVKdOHdntdvMHzHv16pVnfVF6KaoWLVpo27ZtGjZsmNOx0bZtW6fLRYvSw9ixY9WtWzfVqFFDZcqUkbu7u2rWrKmhQ4dq9erVee5vwMpshnGVvvkJADAZhpHn95Hatm1rfs9k69atat68+bVuDbhmOA6urZiYGLVv317Sxe9+RUVFlW5DAIqFM2wAcA388MMP6tOnj1asWKHff/9d27ZtU3h4uPlHat26dc0flgVuVBwHAFB0DDoCANdAVlaWFixYkOdlU+XLl1dUVNRVuwwNsAqOAwAoOv6rCADXQO3atfXEE0/o1ltvVZkyZeTh4aE6depo2LBh2rZtm9q2bVvaLQJXHccBABQd32EDAAAAAIviDBsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUW6l3cDNJCsrS4cPH1b58uVls9lKux0AAAAApcQwDJ06dUoBAQFyccn/PBqB7Ro6fPiwAgMDS7sNAAAAABbxxx9/qFq1avnOJ7BdQ+XLl5d0cac4HI5S7gYAAABAaUlNTVVgYKCZEfJDYLuGsi+DdDgcBDYAAAAAl/2qFIOOAAAAAIBFlWpgmzVrlpo0aWKecQoODtby5cvN+efOnVN4eLgqVaqkcuXKqWfPnjp69KjTMg4ePKguXbqoTJky8vPz08iRI5WRkeFUExMToxYtWsjDw0N16tRRVFRUrl5mzJihmjVrytPTU0FBQdq0aZPT/ML0AgAAAAAlqVQDW7Vq1TR58mTFxcVpy5Ytuu+++9StWzft3LlTkvTcc8/pm2++0aJFi7R27VodPnxYPXr0MJ+fmZmpLl266Pz589qwYYPmzZunqKgoRUZGmjWJiYnq0qWL2rdvr4SEBI0YMUKDBg3SihUrzJrPPvtMERERGjdunLZu3aqmTZsqNDRUx44dM2su1wsAAAAAlDSbYRhGaTeRU8WKFfXWW2/pkUceUeXKlTV//nw98sgjkqTdu3erfv36io2NVdu2bbV8+XJ17dpVhw8fVpUqVSRJs2fP1ujRo3X8+HHZ7XaNHj1ay5Yt044dO8x19O7dW8nJyYqOjpYkBQUFqXXr1nr//fclXRx+PzAwUM8++6zGjBmjlJSUy/ZSGKmpqfL29lZKSgrfYQMAACgFhmEoIyNDmZmZpd0KbnCurq5yc3PL9ztqhc0Glhl0JDMzU4sWLVJaWpqCg4MVFxenCxcuKCQkxKypV6+eqlevboak2NhYNW7c2AxrkhQaGqphw4Zp586dat68uWJjY52WkV0zYsQISdL58+cVFxensWPHmvNdXFwUEhKi2NhYSSpUL3lJT09Xenq6+Tg1NbX4LxAAAACuyPnz53XkyBGdOXOmtFvBTaJMmTKqWrWq7HZ7sZdR6oFt+/btCg4O1rlz51SuXDktXrxYDRo0UEJCgux2u3x8fJzqq1SpoqSkJElSUlKSU1jLnp89r6Ca1NRUnT17VidPnlRmZmaeNbt37zaXcble8jJp0iRNmDChcC8EAAAArpqsrCwlJibK1dVVAQEBstvtlx2dDyguwzB0/vx5HT9+XImJibrtttsK/HHsgpR6YKtbt64SEhKUkpKizz//XGFhYVq7dm1pt1Uixo4dq4iICPNx9m8tAAAA4No6f/68+bWXMmXKlHY7uAl4eXnJ3d1dv//+u86fPy9PT89iLafUA5vdbledOnUkSS1bttTmzZv17rvvqlevXjp//rySk5OdzmwdPXpU/v7+kiR/f/9cozlmj9yYs+bS0RyPHj0qh8MhLy8vubq6ytXVNc+anMu4XC958fDwkIeHRxFeDQAAAFxNxT3LARRHSbzfLPeOzcrKUnp6ulq2bCl3d3etWrXKnLdnzx4dPHhQwcHBkqTg4GBt377daTTHlStXyuFwqEGDBmZNzmVk12Qvw263q2XLlk41WVlZWrVqlVlTmF4AAAAAoKSV6hm2sWPHqnPnzqpevbpOnTql+fPnKyYmRitWrJC3t7cGDhyoiIgIVaxYUQ6HQ88++6yCg4PNQT46duyoBg0a6Mknn9SUKVOUlJSkl19+WeHh4eaZraFDh+r999/XqFGj9NRTT2n16tVauHChli1bZvYRERGhsLAwtWrVSm3atNG0adOUlpamAQMGSFKhegEAAACAklaqge3YsWPq16+fjhw5Im9vbzVp0kQrVqzQ/fffL0maOnWqXFxc1LNnT6Wnpys0NFQzZ840n+/q6qqlS5dq2LBhCg4OVtmyZRUWFqaJEyeaNbVq1dKyZcv03HPP6d1331W1atX04YcfKjQ01Kzp1auXjh8/rsjISCUlJalZs2aKjo52Gojkcr0AAADgOnXwoPTXX9dufb6+UvXq1259yNP48eO1ZMkSJSQklHYrBbLc77DdyPgdNgAAgNJx7tw5JSYmqlatWs6DPxw8KNWtK507d+2a8fSU9uwpdGjr37+/5s2bp0mTJmnMmDHm9CVLlujhhx/W1f5zvn///kpOTtaSJUsK/RybzabFixere/fuV62vosirn9OnTys9PV2VKlW6auvN932nwmcDy32HDQAAALhm/vrr2oY16eL6inhGz9PTU2+++aZOnjx5lZqypgsXLly1ZZcrV+6qhrWSQmADAAAALC4kJET+/v6aNGlSgXVffPGFGjZsKA8PD9WsWVPvvPOO0/yaNWvqjTfe0FNPPaXy5curevXqmjNnTpF6uffee/WPf/xDo0aNUsWKFeXv76/x48c7rUOSHn74YdlsNvOxJH311Vdq0aKFPD09Vbt2bU2YMEEZGRnmfJvNplmzZumhhx5S2bJl9frrryszM1MDBw5UrVq15OXlpbp16+rdd9/N1ddHH31kbnvVqlU1fPjwAvsZP368mjVrZj6/f//+6t69u95++21VrVpVlSpVUnh4uFNoPHLkiLp06SIvLy/VqlVL8+fPV82aNTVt2rQivYZFQWADAAAALM7V1VVvvPGG3nvvPR06dCjPmri4OD322GPq3bu3tm/frvHjx+uVV15RVFSUU90777yjVq1aKT4+Xs8884yGDRumPXv2FKmfefPmqWzZstq4caOmTJmiiRMnauXKlZKkzZs3S5Lmzp2rI0eOmI9/+OEH9evXT//85z/1yy+/6N///reioqL0+uuvOy17/Pjxevjhh7V9+3Y99dRTysrKUrVq1bRo0SL98ssvioyM1IsvvqiFCxeaz5k1a5bCw8M1ZMgQbd++XV9//bX502H59ZOXNWvW6LffftOaNWs0b948RUVFOb1+/fr10+HDhxUTE6MvvvhCc+bMcRqx/qowcM2kpKQYkoyUlJTSbuUiiRs3btxu3BsA5HD27Fnjl19+Mc6ePes8Iy6udP4bFRdX6N7DwsKMbt26GYZhGG3btjWeeuopwzAMY/HixUbOP+cff/xx4/7773d67siRI40GDRqYj2vUqGE88cQT5uOsrCzDz8/PmDVrVqHWbxiGcc899xh33XWXU03r1q2N0aNHm48lGYsXL3aq6dChg/HGG284Tfvvf/9rVK1a1el5I0aMyLeXbOHh4UbPnj3NxwEBAcZLL72Ub31e/YwbN85o2rSp+TgsLMyoUaOGkZGRYU579NFHjV69ehmGYRi7du0yJBmbN2825+/du9eQZEydOjXP9eb7vjMKnw04wwYAAABcJ958803NmzdPu3btyjVv165duvPOO52m3Xnnndq7d68yMzPNaU2aNDHv22w2+fv7F/ksUc5lSFLVqlUvu4xt27Zp4sSJKleunHkbPHiwjhw5ojNnzph1rVq1yvXcGTNmqGXLlqpcubLKlSunOXPm6ODBg5Iujjx/+PBhdejQoUjbkJeGDRvK1dU1z+3as2eP3Nzc1KJFC3N+nTp1VKFChSteb0FKdVh/AAAAAIXXrl07hYaGauzYserfv3+xluHu7u702GazKSsr66ov4/Tp05owYYJ69OiRa17OERTLli3rNG/BggV64YUX9M477yg4OFjly5fXW2+9pY0bN0qSvLy8itR7QUritSlpBDYAAADgOjJ58mQ1a9ZMdevWdZpev359/fjjj07TfvzxR91+++1OZ42uBXd3d6ezepLUokUL7dmzx/xuWWH9+OOPuuOOO/TMM8+Y03777Tfzfvny5VWzZk2tWrVK7du3L3Q/RVW3bl1lZGQoPj5eLVu2lCTt27fvqo/cSWADAAAAriONGzdW3759NX36dKfpzz//vFq3bq1XX31VvXr1UmxsrN5//33NnDnzmveYHaDuvPNOeXh4qEKFCoqMjFTXrl1VvXp1PfLII3JxcdG2bdu0Y8cOvfbaa/ku67bbbtPHH3+sFStWqFatWvrvf/+rzZs3q1atWmbN+PHjNXToUPn5+alz5846deqUfvzxRz377LP59lNU9erVU0hIiIYMGaJZs2bJ3d1dzz//vLy8vGSz2Yr+IhUS32EDAADAzcvX9+IPWV9Lnp4X13sFJk6cmOtSvRYtWmjhwoVasGCBGjVqpMjISE2cOLHYl05eiXfeeUcrV65UYGCgmjdvLkkKDQ3V0qVL9d1336l169Zq27atpk6dqho1ahS4rKefflo9evRQr169FBQUpL///tvpbJskhYWFadq0aZo5c6YaNmyorl27au/evQX2Uxwff/yxqlSponbt2unhhx/W4MGDVb58+Vw/il2SbP9/1BRcA4X9NfNr5ir+SwAAlDo+3gDkcO7cOSUmJqpWrVq5/7g+eLDIP2R9RXx9perVr936cNUcOnRIgYGB+v777/Mc9KSg911hswGXRAIAACe2CfyDHm48NcrW0Ow7ZyvtWFruv4DdJPlfy26OSYev8m93IV+tAnKPQllYq1ev1unTp9W4cWMdOXJEo0aNUs2aNdWuXbsS7NAZgQ0AAAAACuHChQt68cUXtX//fpUvX1533HGHPvnkk1yjS5YkAhsAAAAAFEJoaKhCQ0Ov6ToZdAQAAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiGCUSAAAAN7Wk00lKPpd8zdbn4+kj/3LX9IffcB0jsAEAAOCmlXQ6ST0X9tT5zPPXbJ12V7u+eOyLmzq0zXlnjmKiYzR/5fzSbsXyuCQSAAAAN63kc8nXNKxJ0vnM80U6ozd+xHi98NQLha5vfUtrxUTHFL2xqySvfp4Y+oRmfjazdBq6znCGDQAAAEAuGRcy5OZ+deJCmbJlVKZsmauy7BsNZ9gAAACA68TTjzytt195W9Nfm64ODTsotFmo5rwzx5z/UNBDkqSRA0eq9S2tzceStHbFWj0R+oTurH2nugV30wf/+kAZGRnm/Na3tNbn8z5XRP8I3V3nbn00/SNlZmbq1edfVbe23XTXrXep59099emHn+bq6+sFX+ux9o/pjlp3qFPzTpry0pQC+5nzzhw9fv/j5vOzzyL+d/Z/1al5J4U0DNGbL76pjAv/199fR//SiCdH6K5b71K3tt0UvThaDwU9pPkf3NiXVXKGDQAAALiOLF20VH2H9NXcb+Zqe9x2TXhugpq2bqqgdkGa9+08dWzSUZH/ilRw+2C5urpKkuI3xmvcP8fphYkvqFlQM/35+596Y9QbkqTBEYPNZX/wrw8U/mK4IiZEyM3NTUaWIb+qfpr070nyruCtn7f8rDdGvSFfP1/d/9D9kqTP532uaROnKXxsuO5of4dOnzqtbZu3SVK+/eRly4Yt8vXz1exFs/VH4h96cdiLur3h7Xq478OSpHH/HKfkE8mavWi23NzdNHXCVJ3468RVeY2thMAGAAAAXEduq3+bGbKq166uhVELtWn9JgW1C1KFShUkSeW9y8vXz9d8zgf/+kBh4WHq+lhXSVK1GtX09Min9d7r7zkFttDuoXqo10PK6ekXnjbv31L9Fm2P267vv/neDGwfTf9IfYf0VZ9Bfcy6hs0aSlK+/eTF4e3QyNdHytXVVTXr1NRdHe7S5vWb9XDfh3Vg3wFt+mGT5n07Tw2aNpAkvfzWy+pxV48ivHLXJwIbAAAAcB2pU7+O02NfP1+d/Otkgc/Z+8te/bzlZ82dPteclpWVpfRz6Tp39pw8vTwlSfWb1s/13IVRC/XNgm+U9GeS0s+l68KFC7q94e2SpBN/ndDxpONqfVfrK90s1b69ttMZuEpVKum3Xb9Jkn7/7Xe5urmqXuN65vzAWoFy+DiueL1WR2ADAAAAriNubs5/wttsNmVlZRX4nLNnzmrI80PUvnP7XPPsHnbzvlcZL6d53331naa/Ol3/fOWfatKqicqULaP/zvqvdsTvkCR5eHoUdzNyuXSAE5tsyjIK3q6bAYENAAAAuIG4ubspK9M56NRtVFe///a7AmsFFmlZ2zZvU+OWjfVo/0fNaYd+P2TeL1uurAICA7R5/Wa1urNVofspqhq31lBmRqb27Nij+k0ungX8I/EPpSanXtFyrweMEgkAAADcQAKqBWjT+k3669hfZqAZ9NwgLft8mT741wf6bc9vStybqO+++k6z3pxV4LICawVq18+7FBsTq99/+12zpszSL9t+caoZHDFYn8z5RAv+s0AH9x/U7u279dlHnxXYT1HVrFNTbe5uozdGvaGd8Tu1Z8cevTHqDXl4eshmsxVrmdcLAhsAAABuWj6ePrK72i9fWILsrnb5ePpcteX/M/Kf2rRuk7q27qonQp+QJAXfG6yp86bqp7U/KeyBMA14cIDmfzBf/tX8C1xWjyd6qH3n9npx2Isa8OAApZxM0SNhjzjVdH2sqyLGR+jzeZ+r13299FzYc/oj8Y8C+ymOCe9OUMXKFTWk5xCNHDhS3ft2V9lyZeXhUXKXZVqRzTAMo7SbuFmkpqbK29tbKSkpcjgs8AXJG/xfIwDc5Ph4KzbbBD4fcOOpUbaGZt85W763+Ob6UlDS6SQln0u+Zr34ePrIv1zBQQmXd/TwUXVt3VUzFsxQm7vbFPp5rQLyvnTzajh37pwSExNVq1YteXp6Os0rbDbgO2wAAAC4qfmX8ydAXQc2r9+sM2fOqE69Ovrr6F967/X3FBAYoBZtW5R2a1cVgQ0AAACA5WVkZGjm5Jn68/c/VbZcWTVp1USvvv9qrtElbzQ39tYBAAAAuCEE3xus4HuDS7uNa45BRwAAAADAoghsAAAAuOEZ//9/YjwiXEMlMb4jgQ0AAAA3vL/T/9b5zPPShdLuBDeTM2fOSJLc3d2LvQy+wwYAAIAbXlpGmr7+/Wv1sfeRj3wkd0n8gsVN6dy5c1d9HYZh6MyZMzp27Jh8fHzk6upa7GUR2AAAAHBTmLtvriTpoRoPye5ql43EdlNKTEu8Zuvy8fGRv/+V/WQEgQ0AAAA3BUOGPtr3kRYkLpCvpy+B7Sa1e/jua7Ied3f3Kzqzlo3ABgAAgJvKmcwzOph2sLTbQCnx9PQs7RaKhEFHAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwqFINbJMmTVLr1q1Vvnx5+fn5qXv37tqzZ49Tzb333iubzeZ0Gzp0qFPNwYMH1aVLF5UpU0Z+fn4aOXKkMjIynGpiYmLUokULeXh4qE6dOoqKisrVz4wZM1SzZk15enoqKChImzZtcpp/7tw5hYeHq1KlSipXrpx69uypo0ePlsyLAQAAAACXKNXAtnbtWoWHh+unn37SypUrdeHCBXXs2FFpaWlOdYMHD9aRI0fM25QpU8x5mZmZ6tKli86fP68NGzZo3rx5ioqKUmRkpFmTmJioLl26qH379kpISNCIESM0aNAgrVixwqz57LPPFBERoXHjxmnr1q1q2rSpQkNDdezYMbPmueee0zfffKNFixZp7dq1Onz4sHr06HEVXyEAAAAANzObYRhGaTeR7fjx4/Lz89PatWvVrl07SRfPsDVr1kzTpk3L8znLly9X165ddfjwYVWpUkWSNHv2bI0ePVrHjx+X3W7X6NGjtWzZMu3YscN8Xu/evZWcnKzo6GhJUlBQkFq3bq33339fkpSVlaXAwEA9++yzGjNmjFJSUlS5cmXNnz9fjzzyiCRp9+7dql+/vmJjY9W2bdvLbl9qaqq8vb2VkpIih8NR7NepxNhspd0BAFw91vl4u+7YJvD5AODGZYyzxudDYbOBpb7DlpKSIkmqWLGi0/RPPvlEvr6+atSokcaOHaszZ86Y82JjY9W4cWMzrElSaGioUlNTtXPnTrMmJCTEaZmhoaGKjY2VJJ0/f15xcXFONS4uLgoJCTFr4uLidOHCBaeaevXqqXr16mbNpdLT05Wamup0AwAAAIDCcivtBrJlZWVpxIgRuvPOO9WoUSNz+uOPP64aNWooICBAP//8s0aPHq09e/boyy+/lCQlJSU5hTVJ5uOkpKQCa1JTU3X27FmdPHlSmZmZedbs3r3bXIbdbpePj0+umuz1XGrSpEmaMGFCEV8JAAAAALjIMoEtPDxcO3bs0Pr1652mDxkyxLzfuHFjVa1aVR06dNBvv/2mW2+99Vq3WSRjx45VRESE+Tg1NVWBgYGl2BEAAACA64klLokcPny4li5dqjVr1qhatWoF1gYFBUmS9u3bJ0ny9/fPNVJj9mN/f/8CaxwOh7y8vOTr6ytXV9c8a3Iu4/z580pOTs635lIeHh5yOBxONwAAAAAorFINbIZhaPjw4Vq8eLFWr16tWrVqXfY5CQkJkqSqVatKkoKDg7V9+3an0RxXrlwph8OhBg0amDWrVq1yWs7KlSsVHBwsSbLb7WrZsqVTTVZWllatWmXWtGzZUu7u7k41e/bs0cGDB80aAAAAAChJpXpJZHh4uObPn6+vvvpK5cuXN78L5u3tLS8vL/3222+aP3++HnjgAVWqVEk///yznnvuObVr105NmjSRJHXs2FENGjTQk08+qSlTpigpKUkvv/yywsPD5eHhIUkaOnSo3n//fY0aNUpPPfWUVq9erYULF2rZsmVmLxEREQoLC1OrVq3Upk0bTZs2TWlpaRowYIDZ08CBAxUREaGKFSvK4XDo2WefVXBwcKFGiAQAAACAoirVwDZr1ixJF4fuz2nu3Lnq37+/7Ha7vv/+ezM8BQYGqmfPnnr55ZfNWldXVy1dulTDhg1TcHCwypYtq7CwME2cONGsqVWrlpYtW6bnnntO7777rqpVq6YPP/xQoaGhZk2vXr10/PhxRUZGKikpSc2aNVN0dLTTQCRTp06Vi4uLevbsqfT0dIWGhmrmzJlX6dUBAAAAcLOz1O+w3ej4HTYAuIb4eCs2focNwI2M32EDAAAAAJQIAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAAAAwKIIbAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsqlQD26RJk9S6dWuVL19efn5+6t69u/bs2eNUc+7cOYWHh6tSpUoqV66cevbsqaNHjzrVHDx4UF26dFGZMmXk5+enkSNHKiMjw6kmJiZGLVq0kIeHh+rUqaOoqKhc/cyYMUM1a9aUp6engoKCtGnTpiL3AgAAAAAlpVQD29q1axUeHq6ffvpJK1eu1IULF9SxY0elpaWZNc8995y++eYbLVq0SGvXrtXhw4fVo0cPc35mZqa6dOmi8+fPa8OGDZo3b56ioqIUGRlp1iQmJqpLly5q3769EhISNGLECA0aNEgrVqwwaz777DNFRERo3Lhx2rp1q5o2barQ0FAdO3as0L0AAAAAQEmyGYZhlHYT2Y4fPy4/Pz+tXbtW7dq1U0pKiipXrqz58+frkUcekSTt3r1b9evXV2xsrNq2bavly5era9euOnz4sKpUqSJJmj17tkaPHq3jx4/Lbrdr9OjRWrZsmXbs2GGuq3fv3kpOTlZ0dLQkKSgoSK1bt9b7778vScrKylJgYKCeffZZjRkzplC9XE5qaqq8vb2VkpIih8NRoq9dsdhspd0BAFw91vl4u+7YJvD5AODGZYyzxudDYbOBpb7DlpKSIkmqWLGiJCkuLk4XLlxQSEiIWVOvXj1Vr15dsbGxkqTY2Fg1btzYDGuSFBoaqtTUVO3cudOsybmM7JrsZZw/f15xcXFONS4uLgoJCTFrCtMLAAAAAJQkt9JuIFtWVpZGjBihO++8U40aNZIkJSUlyW63y8fHx6m2SpUqSkpKMmtyhrXs+dnzCqpJTU3V2bNndfLkSWVmZuZZs3v37kL3cqn09HSlp6ebj1NTUy/3MgAAAACAyTJn2MLDw7Vjxw4tWLCgtFspMZMmTZK3t7d5CwwMLO2WAAAAAFxHLBHYhg8frqVLl2rNmjWqVq2aOd3f31/nz59XcnKyU/3Ro0fl7+9v1lw6UmP248vVOBwOeXl5ydfXV66urnnW5FzG5Xq51NixY5WSkmLe/vjjj0K8GgAAAABwUakGNsMwNHz4cC1evFirV69WrVq1nOa3bNlS7u7uWrVqlTltz549OnjwoIKDgyVJwcHB2r59u9NojitXrpTD4VCDBg3MmpzLyK7JXobdblfLli2darKysrRq1SqzpjC9XMrDw0MOh8PpBgAAAACFVarfYQsPD9f8+fP11VdfqXz58uZ3wby9veXl5SVvb28NHDhQERERqlixohwOh5599lkFBwebozJ27NhRDRo00JNPPqkpU6YoKSlJL7/8ssLDw+Xh4SFJGjp0qN5//32NGjVKTz31lFavXq2FCxdq2bJlZi8REREKCwtTq1at1KZNG02bNk1paWkaMGCA2dPlegEAAACAklSqgW3WrFmSpHvvvddp+ty5c9W/f39J0tSpU+Xi4qKePXsqPT1doaGhmjlzplnr6uqqpUuXatiwYQoODlbZsmUVFhamiRMnmjW1atXSsmXL9Nxzz+ndd99VtWrV9OGHHyo0NNSs6dWrl44fP67IyEglJSWpWbNmio6OdhqI5HK9AAAAAEBJstTvsN3o+B02ALiG+HgrNn6HDcCNjN9hAwAAAACUCAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFHFCmy1a9fWI488kmv6Sy+9pF69el1xUwAAAAAAya04Tzpw4ID8/f1zTf/++++1ZcuWK24KAAAAAFDEwPbxxx+b948fP+70OC0tTbt27ZLdbi+57gAAAADgJlakwNa/f3/ZbDbZbDbt379fAwYMcJpvGIaaNGlSog0CAAAAwM2qyJdEGoYhm80mwzCcpnt5ealevXqaPn16iTUHAAAAADezIgW2rKwsSZKLi4vatm2rDRs2XJWmAAAAAADFHHRkzZo1cjgcJd0LAAAAACCHYgW2e+65R7/++qvmzJmjo0eP5ro8MjIyskSaAwAAAICbWbEC20cffaSnn37avETyUgQ2AAAAALhyxQpsr732mjIzM0u6FwAAAABADi7FedLRo0fl7e2tbdu26cKFC8rKynK6AQAAAACuXLECW/v27VWxYkU1btxYrq6uJd0TAAAAAEDFvCTy0Ucf1ZAhQ9S7d289/vjj8vHxcZrfrl27kugNAAAAAG5qNuPSIR4LwcXFRTabLe8F2mzKyMi44sZuRKmpqfL29lZKSoo1fhYhn30IADeEon+84f+zTeDzAcCNyxhnjc+HwmaDYp1hk5RrKH8AAAAAQMkqVmBLTEws6T4AAAAAAJcoVmCrUaNGSfcBAAAAALhEsQLbU089le88m82m//znP8VuCAAAAABwUbECW1RUVJ6DjhiGQWADAAAAgBJSrMDWrl07p8CWkpKi7du3yzAM3X333SXWHAAAAADczIr1w9kxMTFas2aNedu6dau2b98uh8Ohrl27Fno569at04MPPqiAgADZbDYtWbLEaX7//v1ls9mcbp06dXKqOXHihPr27SuHwyEfHx8NHDhQp0+fdqr5+eefdffdd8vT01OBgYGaMmVKrl4WLVqkevXqydPTU40bN9a3337rNN8wDEVGRqpq1ary8vJSSEiI9u7dW+htBQAAAICiKlZgy0u9evXUrFkzvffee4V+Tlpampo2baoZM2bkW9OpUycdOXLEvH366adO8/v27audO3dq5cqVWrp0qdatW6chQ4aY81NTU9WxY0fVqFFDcXFxeuuttzR+/HjNmTPHrNmwYYP69OmjgQMHKj4+Xt27d1f37t21Y8cOs2bKlCmaPn26Zs+erY0bN6ps2bIKDQ3VuXPnCr29AAAAAFAUxfrh7I8//tjpcWZmpn799Ve9/fbbKlOmjFJSUoreiM2mxYsXq3v37ua0/v37Kzk5OdeZt2y7du1SgwYNtHnzZrVq1UqSFB0drQceeECHDh1SQECAZs2apZdeeklJSUmy2+2SpDFjxmjJkiXavXu3JKlXr15KS0vT0qVLzWW3bdtWzZo10+zZs2UYhgICAvT888/rhRdekHTxMtAqVaooKipKvXv3LtQ28sPZAHAN8XuhxcYPZwO4kd0UP5ydfanipQzD0D333FOcReYrJiZGfn5+qlChgu677z699tprqlSpkiQpNjZWPj4+ZliTpJCQELm4uGjjxo16+OGHFRsbq3bt2plhTZJCQ0P15ptv6uTJk6pQoYJiY2MVERHhtN7Q0FAzKCYmJiopKUkhISHmfG9vbwUFBSk2NjbfwJaenq709HTzcWpq6hW/HgAAAABuHsW+JNIwDKdb5cqV1adPH33wwQcl1lynTp308ccfa9WqVXrzzTe1du1ade7cWZmZmZKkpKQk+fn5OT3Hzc1NFStWVFJSkllTpUoVp5rsx5eryTk/5/PyqsnLpEmT5O3tbd4CAwOLtP0AAAAAbm7FOsOWlZVV0n3kKeeZq8aNG6tJkya69dZbFRMTow4dOlyTHq7E2LFjnc7cpaamEtoAAAAAFNoVDTpy7tw5xcXFKS4u7poMvlG7dm35+vpq3759kiR/f38dO3bMqSYjI0MnTpyQv7+/WXP06FGnmuzHl6vJOT/n8/KqyYuHh4ccDofTDQAAAAAKq9iB7Y033pCvr6/atGmjNm3ayNfXV5MnTy7J3nI5dOiQ/v77b1WtWlWSFBwcrOTkZMXFxZk1q1evVlZWloKCgsyadevW6cKFC2bNypUrVbduXVWoUMGsWbVqldO6Vq5cqeDgYElSrVq15O/v71STmpqqjRs3mjUAAAAAUNKKFdg++ugjvfzyyzpz5oz5HbYzZ87opZdeUlRUVKGXc/r0aSUkJCghIUHSxcE9EhISdPDgQZ0+fVojR47UTz/9pAMHDmjVqlXq1q2b6tSpo9DQUElS/fr11alTJw0ePFibNm3Sjz/+qOHDh6t3794KCAiQJD3++OOy2+0aOHCgdu7cqc8++0zvvvuu06WK//znPxUdHa133nlHu3fv1vjx47VlyxYNHz5c0sURLEeMGKHXXntNX3/9tbZv365+/fopICDAaVRLAAAAAChJxRrWv0WLFkpISNDDDz9sfs/s008/1ZIlS9S8eXOnM14FiYmJUfv27XNNDwsL06xZs9S9e3fFx8crOTlZAQEB6tixo1599VWnwT9OnDih4cOH65tvvpGLi4t69uyp6dOnq1y5cmbNzz//rPDwcG3evFm+vr569tlnNXr0aKd1Llq0SC+//LIOHDig2267TVOmTNEDDzxgzjcMQ+PGjdOcOXOUnJysu+66SzNnztTtt99e6NeNYf0B4BpiWP9iY1h/ADey621Y/2IFNi8vL1WtWlX79+93ml6rVi0dPXpUZ86cKXrHNwECGwBcQwS2YiOwAbiRXW+BrViXRLq5uencuXPKyMgwp124cEHnzp2Tq6trcRYJAAAAALhEsYb1b9asmTZs2KB27dqpR48ekqQvv/xSx44d05133lmiDQIAAADAzapYgW3kyJHq3r27Nm7cqI0bN0q6+B0vSRo1alTJdQcAAAAAN7FiXRL50EMP6eOPP1ZgYKA5SmT16tX1v//9T127di3pHgEAAADgplSkM2wHDhzQunXrVLduXT3xxBN64okndPz4cUnSvn37tHfvXh04cEA1a9a8Gr0CAAAAwE2lSGfYJk+erAEDBjj9CHXlypVVuXJlnTlzRgMGDLjqP54NAAAAADeLIgW2NWvWyOFw6K677so1r0OHDvLx8dGqVatKrDkAAAAAuJkVKbAdOnRI1atXz3d+YGCg/vzzzytuCgAAAABQxMDm5uam33//XVlZWbnmZWZm6sCBA3J3dy+x5gAAAADgZlakwFa/fn2dOnVKL730Uq55r7zyilJTU1W/fv0Saw4AAAAAbmZFGiXyscce06ZNmzRlyhStWLFCd999t2w2m9avX6/4+HjZbDb16tXravUKAAAAADcVm5H9i9eFkJ6eruDgYCUkJMhmsznNMwxDzZs3V2xsrOx2e4k3eiNITU2Vt7e3UlJS5HA4Srsd6ZJ9CAA3lMJ/vOEStgl8PgC4cRnjrPH5UNhsUKRLIj08PLR69Wr16dNHrq6u5o9mu7q66vHHH9f3339PWAMAAACAElKkSyIlycfHR5988olmzZqlX3/9VYZhqG7dutY4YwQAAAAAN5AiB7ZsDodDrVq1KsleAAAAAAA5FOmSSAAAAADAtUNgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwAYAAAAAFkVgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwAYAAAAAFkVgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwAYAAAAAFkVgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwAYAAAAAFkVgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRpRrY1q1bpwcffFABAQGy2WxasmSJ03zDMBQZGamqVavKy8tLISEh2rt3r1PNiRMn1LdvXzkcDvn4+GjgwIE6ffq0U83PP/+su+++W56engoMDNSUKVNy9bJo0SLVq1dPnp6eaty4sb799tsi9wIAAAAAJalUA1taWpqaNm2qGTNm5Dl/ypQpmj59umbPnq2NGzeqbNmyCg0N1blz58yavn37aufOnVq5cqWWLl2qdevWaciQIeb81NRUdezYUTVq1FBcXJzeeustjR8/XnPmzDFrNmzYoD59+mjgwIGKj49X9+7d1b17d+3YsaNIvQAAAABASbIZhmGUdhOSZLPZtHjxYnXv3l3SxTNaAQEBev755/XCCy9IklJSUlSlShVFRUWpd+/e2rVrlxo0aKDNmzerVatWkqTo6Gg98MADOnTokAICAjRr1iy99NJLSkpKkt1ulySNGTNGS5Ys0e7duyVJvXr1UlpampYuXWr207ZtWzVr1kyzZ88uVC+FkZqaKm9vb6WkpMjhcJTI63ZFbLbS7gAArh5rfLxdl2wT+HwAcOMyxlnj86Gw2cCy32FLTExUUlKSQkJCzGne3t4KCgpSbGysJCk2NlY+Pj5mWJOkkJAQubi4aOPGjWZNu3btzLAmSaGhodqzZ49Onjxp1uRcT3ZN9noK00te0tPTlZqa6nQDAAAAgMKybGBLSkqSJFWpUsVpepUqVcx5SUlJ8vPzc5rv5uamihUrOtXktYyc68ivJuf8y/WSl0mTJsnb29u8BQYGXmarAQAAAOD/WDaw3QjGjh2rlJQU8/bHH3+UdksAAAAAriOWDWz+/v6SpKNHjzpNP3r0qDnP399fx44dc5qfkZGhEydOONXktYyc68ivJuf8y/WSFw8PDzkcDqcbAAAAABSWZQNbrVq15O/vr1WrVpnTUlNTtXHjRgUHB0uSgoODlZycrLi4OLNm9erVysrKUlBQkFmzbt06XbhwwaxZuXKl6tatqwoVKpg1OdeTXZO9nsL0AgAAAAAlrVQD2+nTp5WQkKCEhARJFwf3SEhI0MGDB2Wz2TRixAi99tpr+vrrr7V9+3b169dPAQEB5kiS9evXV6dOnTR48GBt2rRJP/74o4YPH67evXsrICBAkvT444/Lbrdr4MCB2rlzpz777DO9++67ioiIMPv45z//qejoaL3zzjvavXu3xo8fry1btmj48OGSVKheAAAAAKCkuZXmyrds2aL27dubj7NDVFhYmKKiojRq1CilpaVpyJAhSk5O1l133aXo6Gh5enqaz/nkk080fPhwdejQQS4uLurZs6emT59uzvf29tZ3332n8PBwtWzZUr6+voqMjHT6rbY77rhD8+fP18svv6wXX3xRt912m5YsWaJGjRqZNYXpBQAAAABKkmV+h+1mwO+wAcA1xMdbsfE7bABuZPwOGwAAAACgRBDYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKEsHtvHjx8tmsznd6tWrZ84/d+6cwsPDValSJZUrV049e/bU0aNHnZZx8OBBdenSRWXKlJGfn59GjhypjIwMp5qYmBi1aNFCHh4eqlOnjqKionL1MmPGDNWsWVOenp4KCgrSpk2brso2AwAAAEA2Swc2SWrYsKGOHDli3tavX2/Oe+655/TNN99o0aJFWrt2rQ4fPqwePXqY8zMzM9WlSxedP39eGzZs0Lx58xQVFaXIyEizJjExUV26dFH79u2VkJCgESNGaNCgQVqxYoVZ89lnnykiIkLjxo3T1q1b1bRpU4WGhurYsWPX5kUAAAAAcFOyGYZhlHYT+Rk/fryWLFmihISEXPNSUlJUuXJlzZ8/X4888ogkaffu3apfv75iY2PVtm1bLV++XF27dtXhw4dVpUoVSdLs2bM1evRoHT9+XHa7XaNHj9ayZcu0Y8cOc9m9e/dWcnKyoqOjJUlBQUFq3bq13n//fUlSVlaWAgMD9eyzz2rMmDGF3p7U1FR5e3srJSVFDoejuC9LybHZSrsDALh6rPvxZnm2CXw+ALhxGeOs8flQ2Gxg+TNse/fuVUBAgGrXrq2+ffvq4MGDkqS4uDhduHBBISEhZm29evVUvXp1xcbGSpJiY2PVuHFjM6xJUmhoqFJTU7Vz506zJucysmuyl3H+/HnFxcU51bi4uCgkJMSsyU96erpSU1OdbgAAAABQWJYObEFBQYqKilJ0dLRmzZqlxMRE3X333Tp16pSSkpJkt9vl4+Pj9JwqVaooKSlJkpSUlOQU1rLnZ88rqCY1NVVnz57VX3/9pczMzDxrspeRn0mTJsnb29u8BQYGFvk1AAAAAHDzcivtBgrSuXNn836TJk0UFBSkGjVqaOHChfLy8irFzgpn7NixioiIMB+npqYS2gAAAAAUmqXPsF3Kx8dHt99+u/bt2yd/f3+dP39eycnJTjVHjx6Vv7+/JMnf3z/XqJHZjy9X43A45OXlJV9fX7m6uuZZk72M/Hh4eMjhcDjdAAAAAKCwrqvAdvr0af3222+qWrWqWrZsKXd3d61atcqcv2fPHh08eFDBwcGSpODgYG3fvt1pNMeVK1fK4XCoQYMGZk3OZWTXZC/DbrerZcuWTjVZWVlatWqVWQMAAAAAV4OlA9sLL7ygtWvX6sCBA9qwYYMefvhhubq6qk+fPvL29tbAgQMVERGhNWvWKC4uTgMGDFBwcLDatm0rSerYsaMaNGigJ598Utu2bdOKFSv08ssvKzw8XB4eHpKkoUOHav/+/Ro1apR2796tmTNnauHChXruuefMPiIiIvTBBx9o3rx52rVrl4YNG6a0tDQNGDCgVF4XAAAAADcHS3+H7dChQ+rTp4/+/vtvVa5cWXfddZd++uknVa5cWZI0depUubi4qGfPnkpPT1doaKhmzpxpPt/V1VVLly7VsGHDFBwcrLJlyyosLEwTJ040a2rVqqVly5bpueee07vvvqtq1arpww8/VGhoqFnTq1cvHT9+XJGRkUpKSlKzZs0UHR2dayASAAAAAChJlv4dthsNv8MGANcQH2/Fxu+wAbiR8TtsAAAAAIASQWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGwAAAAAYFEENgAAAACwKAIbAAAAAFgUgQ0AAAAALIrABgAAAAAWRWADAAAAAIsisAEAAACARRHYAAAAAMCiCGxFNGPGDNWsWVOenp4KCgrSpk2bSrslAAAAADcoAlsRfPbZZ4qIiNC4ceO0detWNW3aVKGhoTp27FhptwYAAADgBkRgK4J//etfGjx4sAYMGKAGDRpo9uzZKlOmjD766KPSbg0AAADADcittBu4Xpw/f15xcXEaO3asOc3FxUUhISGKjY3N8znp6elKT083H6ekpEiSUlNTr26zAACJ/9YW37nSbgAArh6r/C2e3YdhGAXWEdgK6a+//lJmZqaqVKniNL1KlSravXt3ns+ZNGmSJkyYkGt6YGDgVekRAJCDt3dpdwAAsCDvydb6fDh16pS8C/jMIrBdRWPHjlVERIT5OCsrSydOnFClSpVks9lKsbObS2pqqgIDA/XHH3/I4XCUdjs3LfaDNbAfSh/7wBrYD9bAfrAG9kPpMAxDp06dUkBAQIF1BLZC8vX1laurq44ePeo0/ejRo/L398/zOR4eHvLw8HCa5uPjc7VaxGU4HA7+I2QB7AdrYD+UPvaBNbAfrIH9YA3sh2uvoDNr2Rh0pJDsdrtatmypVatWmdOysrK0atUqBQcHl2JnAAAAAG5UnGErgoiICIWFhalVq1Zq06aNpk2bprS0NA0YMKC0WwMAAABwAyKwFUGvXr10/PhxRUZGKikpSc2aNVN0dHSugUhgLR4eHho3blyuy1NxbbEfrIH9UPrYB9bAfrAG9oM1sB+szWZcbhxJAAAAAECp4DtsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwIbr3okTJ9S3b185HA75+Pho4MCBOn36dIH1zz77rOrWrSsvLy9Vr15d//jHP5SSkuJUZ7PZct0WLFhwtTfnujFjxgzVrFlTnp6eCgoK0qZNmwqsX7RokerVqydPT081btxY3377rdN8wzAUGRmpqlWrysvLSyEhIdq7d+/V3IQbQlH2wwcffKC7775bFSpUUIUKFRQSEpKrvn///rne9506dbram3HdK8p+iIqKyvUae3p6OtVwPBRPUfbDvffem+d/57t06WLWcDwUzbp16/Tggw8qICBANptNS5YsuexzYmJi1KJFC3l4eKhOnTqKiorKVVPUz5ubXVH3w5dffqn7779flStXlsPhUHBwsFasWOFUM378+FzHQr169a7iViAnAhuue3379tXOnTu1cuVKLV26VOvWrdOQIUPyrT98+LAOHz6st99+Wzt27FBUVJSio6M1cODAXLVz587VkSNHzFv37t2v4pZcPz777DNFRERo3Lhx2rp1q5o2barQ0FAdO3Ysz/oNGzaoT58+GjhwoOLj49W9e3d1795dO3bsMGumTJmi6dOna/bs2dq4caPKli2r0NBQnTt37lpt1nWnqPshJiZGffr00Zo1axQbG6vAwEB17NhRf/75p1Ndp06dnN73n3766bXYnOtWUfeDJDkcDqfX+Pfff3eaz/FQdEXdD19++aXTPtixY4dcXV316KOPOtVxPBReWlqamjZtqhkzZhSqPjExUV26dFH79u2VkJCgESNGaNCgQU5hoTjH182uqPth3bp1uv/++/Xtt98qLi5O7du314MPPqj4+HinuoYNGzodC+vXr78a7SMvBnAd++WXXwxJxubNm81py5cvN2w2m/Hnn38WejkLFy407Ha7ceHCBXOaJGPx4sUl2e4No02bNkZ4eLj5ODMz0wgICDAmTZqUZ/1jjz1mdOnSxWlaUFCQ8fTTTxuGYRhZWVmGv7+/8dZbb5nzk5OTDQ8PD+PTTz+9CltwYyjqfrhURkaGUb58eWPevHnmtLCwMKNbt24l3eoNraj7Ye7cuYa3t3e+y+N4KJ4rPR6mTp1qlC9f3jh9+rQ5jeOh+ArzGTpq1CijYcOGTtN69eplhIaGmo+vdL/e7Ir7t0yDBg2MCRMmmI/HjRtnNG3atOQaQ5Fwhg3XtdjYWPn4+KhVq1bmtJCQELm4uGjjxo2FXk5KSoocDofc3Jx/Sz48PFy+vr5q06aNPvroIxn8bKHOnz+vuLg4hYSEmNNcXFwUEhKi2NjYPJ8TGxvrVC9JoaGhZn1iYqKSkpKcary9vRUUFJTvMm92xdkPlzpz5owuXLigihUrOk2PiYmRn5+f6tatq2HDhunvv/8u0d5vJMXdD6dPn1aNGjUUGBiobt26aefOneY8joeiK4nj4T//+Y969+6tsmXLOk3neLh6LvfZUBL7FUWXlZWlU6dO5fps2Lt3rwICAlS7dm317dtXBw8eLKUObz4ENlzXkpKS5Ofn5zTNzc1NFStWVFJSUqGW8ddff+nVV1/NdRnlxIkTtXDhQq1cuVI9e/bUM888o/fee6/Eer9e/fXXX8rMzFSVKlWcplepUiXf1zwpKanA+uz/L8oyb3bF2Q+XGj16tAICApz+GOrUqZM+/vhjrVq1Sm+++abWrl2rzp07KzMzs0T7v1EUZz/UrVtXH330kb766iv973//U1ZWlu644w4dOnRIEsdDcVzp8bBp0ybt2LFDgwYNcprO8XB15ffZkJqaqrNnz5bIf+dQdG+//bZOnz6txx57zJwWFBRkfoVk1qxZSkxM1N13361Tp06VYqc3D7fLlwDX3pgxY/Tmm28WWLNr164rXk9qaqq6dOmiBg0aaPz48U7zXnnlFfN+8+bNlZaWprfeekv/+Mc/rni9QGmbPHmyFixYoJiYGKcBL3r37m3eb9y4sZo0aaJbb71VMTEx6tChQ2m0esMJDg5WcHCw+fiOO+5Q/fr19e9//1uvvvpqKXZ28/rPf/6jxo0bq02bNk7TOR5ws5k/f74mTJigr776yukfxDt37mzeb9KkiYKCglSjRg0tXLgwzzEAULI4wwZLev7557Vr164Cb7Vr15a/v3+uLx5nZGToxIkT8vf3L3Adp06dUqdOnVS+fHktXrxY7u7uBdYHBQXp0KFDSk9Pv+Ltu575+vrK1dVVR48edZp+9OjRfF9zf3//Auuz/78oy7zZFWc/ZHv77bc1efJkfffdd2rSpEmBtbVr15avr6/27dt3xT3fiK5kP2Rzd3dX8+bNzdeY46HormQ/pKWlacGCBYX6o5PjoWTl99ngcDjk5eVVIscXCm/BggUaNGiQFi5cmOtS1Uv5+Pjo9ttv51i4RghssKTKlSurXr16Bd7sdruCg4OVnJysuLg487mrV69WVlaWgoKC8l1+amqqOnbsKLvdrq+//jrXkNp5SUhIUIUKFeTh4VEi23i9stvtatmypVatWmVOy8rK0qpVq5zOGuQUHBzsVC9JK1euNOtr1aolf39/p5rU1FRt3Lgx32Xe7IqzH6SLow+++uqrio6OdvruZ34OHTqkv//+W1WrVi2Rvm80xd0POWVmZmr79u3ma8zxUHRXsh8WLVqk9PR0PfHEE5ddD8dDybrcZ0NJHF8onE8//VQDBgzQp59+6vTTFvk5ffq0fvvtN46Fa6W0Rz0BrlSnTp2M5s2bGxs3bjTWr19v3HbbbUafPn3M+YcOHTLq1q1rbNy40TAMw0hJSTGCgoKMxo0bG/v27TOOHDli3jIyMgzDMIyvv/7a+OCDD4zt27cbe/fuNWbOnGmUKVPGiIyMLJVttJoFCxYYHh4eRlRUlPHLL78YQ4YMMXx8fIykpCTDMAzjySefNMaMGWPW//jjj4abm5vx9ttvG7t27TLGjRtnuLu7G9u3bzdrJk+ebPj4+BhfffWV8fPPPxvdunUzatWqZZw9e/aab9/1oqj7YfLkyYbdbjc+//xzp/f9qVOnDMMwjFOnThkvvPCCERsbayQmJhrff/+90aJFC+O2224zzp07VyrbeD0o6n6YMGGCsWLFCuO3334z4uLijN69exuenp7Gzp07zRqOh6Ir6n7Idtdddxm9evXKNZ3joehOnTplxMfHG/Hx8YYk41//+pcRHx9v/P7774ZhGMaYMWOMJ5980qzfv3+/UaZMGWPkyJHGrl27jBkzZhiurq5GdHS0WXO5/YrcirofPvnkE8PNzc2YMWOG02dDcnKyWfP8888bMTExRmJiovHjjz8aISEhhq+vr3Hs2LFrvn03IwIbrnt///230adPH6NcuXKGw+EwBgwYYP4BahiGkZiYaEgy1qxZYxiGYaxZs8aQlOctMTHRMIyLPw3QrFkzo1y5ckbZsmWNpk2bGrNnzzYyMzNLYQut6b333jOqV69u2O12o02bNsZPP/1kzrvnnnuMsLAwp/qFCxcat99+u2G3242GDRsay5Ytc5qflZVlvPLKK0aVKlUMDw8Po0OHDsaePXuuxaZc14qyH2rUqJHn+37cuHGGYRjGmTNnjI4dOxqVK1c23N3djRo1ahiDBw/mD6NCKMp+GDFihFlbpUoV44EHHjC2bt3qtDyOh+Ip6n+Xdu/ebUgyvvvuu1zL4ngouvw+X7Nf97CwMOOee+7J9ZxmzZoZdrvdqF27tjF37txcyy1ovyK3ou6He+65p8B6w7j4cwtVq1Y17Ha7ccsttxi9evUy9u3bd2037CZmMwzGKQcAAAAAK+I7bAAAAABgUQQ2AAAAALAoAhsAAAAAWBSBDQAAAAAsisAGAAAAABZFYAMAAAAAiyKwAQAAAIBFEdgAAChB/fv3l81m07333lvarQAAbgAENgAAiuDcuXP617/+paCgIDkcDpUpU0a33367nn76ae3fv7+02wMA3GDcSrsBAACuFydPnlSHDh0UHx8vSSpfvrxuvfVWHTx4UHPmzFFwcHApdwgAuNFwhg0AgEIaPny4GdZGjhypEydOaPv27UpJSdHatWtVt27dPJ83ZswYNWzYUD4+PnJ3d1dAQIDCwsJ05MgRsyYpKUl9+/ZV1apV5eHhIX9/f91333369ttvJUmZmZkaO3asateuLU9PT1WsWFGtWrXSW2+9dfU3HABQaghsAAAUQkpKihYuXChJatq0qd588025uf3fhSrt2rXL9wxbdHS0/vzzTwUGBqpOnTpKSkrSxx9/rG7dupk1zzzzjObPn6/Tp0+rUaNGstvtiomJ0aZNmyRJM2bM0OTJk3Xw4EHVrVtXlSpV0vbt27Vs2bKruNUAgNLGJZEAABTCr7/+qoyMDEnS3XffLZvNVujn/ve//1XDhg3l4nLx30k//PBDDR48WJs3b9Zvv/2mW2+9VXv37pUkzZ49W3379pUkHTlyRCkpKZJkzh8wYIA++OADSdLp06e1a9euktlAAIAlcYYNAIBCMAzDvF+UsCZJCQkJat26tcqVKyebzabBgweb8w4fPixJevDBByVJYWFhqlOnjrp27ar//e9/CggIkCR17dpVNptNH374oW655Ra1b99er732mipWrHilmwYAsDDOsAEAUAh169aVm5ubMjIytH79ehmGUajgtn79eoWFhckwDFWqVEkNGjRwOjOWmZkpSXr99dd15513asWKFdqxY4fWrVunZcuWKSYmRsuWLVNoaKi2bt2qRYsWadu2bYqPj1dMTIyioqK0b98+lStX7qpuPwCgdHCGDQCAQvD29tZjjz0mSYqPj9eLL75oXiIpSd9//702bNiQ63kbN240z85t375dmzZtUr9+/XLV/fjjj7rnnns0ffp0rV69WnPmzJEkrVu3TpL0888/q3Llynr99de1dOlSxcXFSZKOHj2qPXv2lOzGAgAsgzNsAAAU0nvvvadffvlFCQkJmjx5smbOnKmaNWvqjz/+0MmTJzV37txcz2nSpIl5v3HjxqpcubKOHTuWq27MmDHavHmzAgMD5e3tbZ6By37+woUL9cYbb6hatWqqXLmyDh48KEkqU6aMbr311quxuQAAC+AMGwAAhVSxYkXFxsbq7bffVuvWrZWVlaU9e/aoQoUKGjRokNq1a5frOffff7/efPNNBQQE6OzZs6pXr55mzZqVq65Xr15q1aqVUlNTtX37dvn4+Kh379769NNPJV0chbJTp07KysrSjh07ZBiG7rvvPi1fvlw+Pj5Xe9MBAKXEZuT8FjUAAAAAwDI4wwYAAAAAFkVgAwAAAACLIrABAAAAgEUR2AAAAADAoghsAAAAAGBRBDYAAAAAsCgCGwAAAABYFIENAAAAACyKwAYAAAAAFkVgAwAAAACLIrABAAAAgEUR2AAAAADAov4fbpJQ1IGg4Q0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categories = pd.unique(y_resampled)\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "colors = {'Non Interacting':'red', 'Interacting':'green'}         \n",
    "labels = list(colors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "plt.bar(categories, count, color=colors.values())\n",
    "plt.xlabel(\"Class\",fontweight=\"bold\")\n",
    "plt.ylabel(\"Count\",fontweight=\"bold\")\n",
    "plt.title(\"Interacting and Non-Interacting RNA Sequences\\n\",fontweight=\"bold\")\n",
    "plt.legend(handles, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b11446",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "473094ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_resampled, y_resampled, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de81464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install \\\n",
    "#    --no-binary lightgbm \\\n",
    "#    --config-settings=cmake.define.USE_OPENMP=OFF \\\n",
    "#    'lightgbm>=4.0.0'\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a900d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred1 = RandomForest(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d1e5fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred2 = XGBoost(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e8b0f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred3 = Pipelining(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c24bd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = SVM(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2608d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   2.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   3.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   3.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   3.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   5.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   5.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   5.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   5.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   5.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=   6.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=   6.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=   6.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=   6.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=   7.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=   8.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=   8.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=   8.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   2.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   3.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   4.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=   5.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=   5.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=   5.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=   5.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=   5.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=   6.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=   6.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=   7.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=   7.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=   7.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=   7.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   2.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   2.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   2.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   2.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   2.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   2.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   2.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   3.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   3.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   3.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   3.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   3.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013271 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   4.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   4.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   4.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   4.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   4.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   4.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   4.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   4.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   5.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   5.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   5.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   5.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   5.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=   5.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=   5.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=   5.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=   5.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=   5.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=   6.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   6.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   6.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   7.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   7.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   7.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   7.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   7.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   8.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=  22.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=  23.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=  22.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=  22.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=  22.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=  25.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=  26.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=  26.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=  26.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=  26.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  31.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  31.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  31.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  31.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  30.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  49.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  50.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  48.8s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  49.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  48.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  56.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  56.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  58.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  59.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  57.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=100; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=100; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=100; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=100; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.05, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   6.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   6.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   6.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   7.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   7.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   7.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   7.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   7.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=  15.8s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=  15.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   8.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   8.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   8.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=  21.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=  22.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=  21.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=  21.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=  21.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=  25.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=  25.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=  24.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=  25.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=  25.9s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  31.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  30.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  30.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  30.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  30.5s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  48.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  47.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  47.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  48.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  48.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  57.0s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  57.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  56.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  57.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  57.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=100; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=100; total time= 1.2min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.1, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   6.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   6.6s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   6.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   6.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   7.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   7.0s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   7.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   7.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   7.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   8.1s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   8.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   8.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   8.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   8.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=  22.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=  24.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=  24.2s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=  22.7s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=  22.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=  25.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=  25.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=  26.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=  24.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=  24.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=  30.6s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=  32.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=  30.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=  30.4s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=  34.2s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  46.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  46.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  49.1s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  49.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  48.4s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  54.3s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  54.3s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  53.9s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  56.5s\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  57.7s\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[CV] END boosting_type=dart, learning_rate=0.2, n_estimators=150, num_leaves=100; total time= 1.1min\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   4.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   4.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   4.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   5.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=31; total time=   4.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   5.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   5.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   5.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   5.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   5.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   6.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   5.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=50, num_leaves=100; total time=   5.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   8.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   8.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   8.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   8.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=31; total time=   8.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   9.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   9.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   9.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=   9.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=50; total time=  10.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  10.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  10.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  12.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  10.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=100, num_leaves=100; total time=  10.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  11.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  11.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  11.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  12.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=31; total time=  12.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  13.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  13.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  13.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  13.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=50; total time=  12.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=  14.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=  14.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=  15.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=  16.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.05, n_estimators=150, num_leaves=100; total time=  15.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   4.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   4.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   4.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   4.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=31; total time=   4.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   5.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   5.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   4.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   4.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=50; total time=   5.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   5.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   5.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   5.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   5.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=50, num_leaves=100; total time=   6.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   8.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   8.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   8.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013300 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   8.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=31; total time=   8.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   9.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   8.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   9.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   8.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=50; total time=   8.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  10.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  10.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  10.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  10.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=100, num_leaves=100; total time=  10.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  11.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  11.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  10.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  11.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=31; total time=  11.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  12.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  12.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  13.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  12.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=50; total time=  12.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=  13.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=  14.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=  13.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=  14.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.1, n_estimators=150, num_leaves=100; total time=  14.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   4.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   4.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   4.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   4.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=31; total time=   4.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   4.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   4.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   4.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   4.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=50; total time=   4.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   5.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   5.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   5.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   5.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=50, num_leaves=100; total time=   5.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   7.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   7.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   7.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   7.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=31; total time=   8.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   8.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   7.8s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   7.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   7.6s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=50; total time=   7.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   8.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   9.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   8.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014952 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   9.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=100, num_leaves=100; total time=   8.7s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   9.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   9.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  10.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=   9.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.293086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=31; total time=  10.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  10.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  10.5s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  10.2s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  10.3s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=50; total time=  10.4s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=  12.0s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175245, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500193 -> initscore=0.000771\n",
      "[LightGBM] [Info] Start training from score 0.000771\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=  12.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=  11.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175109\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350355, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500196 -> initscore=0.000782\n",
      "[LightGBM] [Info] Start training from score 0.000782\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=  11.9s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 175246, number of negative: 175110\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 350356, number of used features: 17\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV] END boosting_type=goss, learning_rate=0.2, n_estimators=150, num_leaves=100; total time=  12.3s\n",
      "[LightGBM] [Info] Number of positive: 219057, number of negative: 218887\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 357\n",
      "[LightGBM] [Info] Number of data points in the train set: 437944, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500194 -> initscore=0.000776\n",
      "[LightGBM] [Info] Start training from score 0.000776\n"
     ]
    }
   ],
   "source": [
    "y_pred5= LightGBM(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9c22fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = LogisticRegressionModel(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80df5dc2",
   "metadata": {},
   "source": [
    "# Calculating Accuracy and MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84bc0f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb696c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews-Coefficient =  0.7581556510296438\n",
      "Accuracy =  0.8779420608423366\n"
     ]
    }
   ],
   "source": [
    "# for RandomForest\n",
    "print(\"Matthews-Coefficient = \", matthews_corrcoef(y_test, y_pred1))\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efbc5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews-Coefficient =  0.49868585358916073\n",
      "Accuracy =  0.7493389595977586\n"
     ]
    }
   ],
   "source": [
    "# for XGBoost\n",
    "print(\"Matthews-Coefficient = \", matthews_corrcoef(y_test, y_pred2))\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d7ed059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews-Coefficient =  0.9898415737997405\n",
      "Accuracy =  0.9949171815703306\n"
     ]
    }
   ],
   "source": [
    "# for RandomForest + XGBoost\n",
    "print(\"Matthews-Coefficient = \", matthews_corrcoef(y_test, y_pred3))\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e37f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews-Coefficient =  0.29785091040594625\n",
      "Accuracy =  0.6468537216917154\n"
     ]
    }
   ],
   "source": [
    "# for SVM\n",
    "print(\"Matthews-Coefficient = \", matthews_corrcoef(y_test, y_pred4))\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62989844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews-Coefficient =  0.6059969903243579\n",
      "Accuracy =  0.8028044553438095\n"
     ]
    }
   ],
   "source": [
    "# for LGBM\n",
    "print(\"Matthews-Coefficient = \", matthews_corrcoef(y_test, y_pred5))\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a355ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews-Coefficient =  0.04468953487107917\n",
      "Accuracy =  0.5223520708032497\n"
     ]
    }
   ],
   "source": [
    "# for Logistic Regression\n",
    "print(\"Matthews-Coefficient = \", matthews_corrcoef(y_test, y_pred6))\n",
    "print(\"Accuracy = \",accuracy_score(y_test, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afde913",
   "metadata": {},
   "source": [
    "# Confusion Matrix for  RandomForest + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42e9d9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cc=confusion_matrix(y_test, y_pred3)\n",
    "\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cc), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595bcf98",
   "metadata": {},
   "source": [
    "# Precesion Recall Curve for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe27f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred1)\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.plot(recall, precision, label = 'Rand')\n",
    "plt.xlabel('recall',fontweight=\"bold\")\n",
    "plt.ylabel('precision',fontweight=\"bold\")\n",
    "plt.title('Hybrid Model PRC Curve',fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79986598",
   "metadata": {},
   "source": [
    "# Precision Recall Curve for RandomForest + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4da81db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred3)\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.plot(recall, precision, label = 'Rand')\n",
    "plt.xlabel('recall',fontweight=\"bold\")\n",
    "plt.ylabel('precision',fontweight=\"bold\")\n",
    "plt.title('Hybrid Model PRC Curve',fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8f8aa",
   "metadata": {},
   "source": [
    "# Precision Recall Curve for LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a70d3a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve\n\u001b[0;32m----> 3\u001b[0m precision, recall, thresholds \u001b[38;5;241m=\u001b[39m precision_recall_curve(y_test, \u001b[43my_pred5\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(recall, precision, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRand\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred5' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred5)\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.plot(recall, precision, label = 'Rand')\n",
    "plt.xlabel('recall',fontweight=\"bold\")\n",
    "plt.ylabel('precision',fontweight=\"bold\")\n",
    "plt.title('Hybrid Model PRC Curve',fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3daa4a",
   "metadata": {},
   "source": [
    "# ROC Curve for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fec188e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8782043502309718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred1)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(fpr, tpr, label='Rand')\n",
    "plt.xlabel('FPR', fontweight=\"bold\")\n",
    "plt.ylabel('TPR', fontweight=\"bold\")\n",
    "plt.title('Hybrid Model ROC curve\\n', fontweight=\"bold\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred1)\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2500f2",
   "metadata": {},
   "source": [
    "# Receiver Operating Characterics  Curve for RandomForest + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5cc27a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred3)\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.plot(fpr, tpr, label = 'Rand')\n",
    "plt.xlabel('FPR',fontweight=\"bold\")\n",
    "plt.ylabel('TPR ',fontweight=\"bold\")\n",
    "plt.title('Hybrid Model ROC curve\\n',fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba560ba",
   "metadata": {},
   "source": [
    "# Training Hybrid Model on entire train data and finding the predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80a30d5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = Pipelining(x_resampled, y_resampled,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eee554",
   "metadata": {},
   "source": [
    "# Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71bffd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateCSV(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f95fb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
